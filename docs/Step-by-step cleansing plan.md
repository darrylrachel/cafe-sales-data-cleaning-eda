# Step-by-step plan (do NOT skip)
ğŸ”¹ Step 1: Profile the raw data (no cleaning yet)

Your only job here is to understand how dirty it is.

Run queries like:
- Row counts
- Null counts per column
- Distinct values for categories
- Min / max for numeric fields
- Date validity checks

ğŸ‘‰ Output goes in your README under â€œData Profilingâ€.

This is where analysts prove they didnâ€™t guess.


## Step 2: Define cleaning rules (before writing SQL)

This is where most people mess up by â€œcleaning on vibes.â€

Create a cleaning rules section (literally write it down):

Examples:

Empty strings â†’ NULL

Negative quantities â†’ invalid â†’ remove

Prices â‰¤ 0 â†’ invalid

Dates that donâ€™t parse â†’ NULL

Category casing standardized (e.g. coffee, Coffee, COFFEE â†’ Coffee)

ğŸ“Œ This becomes documentation, not just code.


## Step 3: Build the stg layer (this is the core)

Key rules:
- No aggregates
- One row in, one row out
- Only cleaning + standardization


ğŸ”¹ Step 4: Validate the staging layer

You now prove the cleaning worked.

Checks like:
- Any remaining NULLs where there shouldnâ€™t be?
- Any negative values left?
- Row counts match expectations?

ğŸ”¹ Step 5: Build the dw layer (analytics-ready)

Now you answer business questions.

Common DW tables:
Fact table
fact_sales
Dimensions
dim_products
dim_dates
dim_categories

Business questions you MUST answer (use these)

Pick 5â€“7 and go deep:
- What are the top-selling products by revenue?
- Which categories drive the most daily sales?
- Whatâ€™s the average order value?
- Are there seasonal patterns?
- Which products have high volume but low revenue?
- How much data was lost due to invalid records?

Folders:
/sql
  â”œâ”€â”€ raw_checks.sql
  â”œâ”€â”€ staging_cleaning.sql
  â”œâ”€â”€ dw_models.sql
/docs
  â”œâ”€â”€ data_quality_report.md
  â”œâ”€â”€ assumptions.md


README sections recruiters love:
- Dataset overview
- Data quality issues found
- Cleaning rules
- Schema design
- Key insights
- Next improvements
